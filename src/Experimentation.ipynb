{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af8551c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import PPO,DQN,A2C\n",
    "from stable_baselines3.common import env_checker\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "import numpy as np\n",
    "from states_generator import StatesGenerator\n",
    "from rl_env import get_benchmark_rewards,compute_reward, critical_task_reward\n",
    "from cades_env import CadesEnv\n",
    "from collections import defaultdict\n",
    "from utils import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b79063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import get_config\n",
    "config, _ = get_config()\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "logdir = f\"../logs/{int(time.time())}/\"\n",
    "models_dir = f\"../models/{int(time.time())}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c50300f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tasks_total_cost': 5204.0,\n",
       " 'nodes_total_capacity': 6400.0,\n",
       " 'extra_capacity': 19.0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env=CadesEnv(config)\n",
    "check_env(env)\n",
    "model = PPO('MultiInputPolicy', env, verbose=1,tensorboard_log=logdir,batch_size=128,device='cuda')\n",
    "env.reset()\n",
    "env.get_env_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bf05920",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_callback = EvalCallback(env, best_model_save_path=models_dir,\n",
    "                             log_path=logdir, eval_freq=10000,\n",
    "                             deterministic=True, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd13a6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ../logs/1677948409/ppo_Test_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4.36     |\n",
      "|    ep_rew_mean     | -14.4    |\n",
      "| time/              |          |\n",
      "|    fps             | 493      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 3.85         |\n",
      "|    ep_rew_mean          | -14.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 460          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071161725 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.69        |\n",
      "|    explained_variance   | -0.00427     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 36.2         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00849     |\n",
      "|    value_loss           | 137          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.24         |\n",
      "|    ep_rew_mean          | -13.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 485          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076111443 |\n",
      "|    clip_fraction        | 0.041        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.68        |\n",
      "|    explained_variance   | -0.069       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0133      |\n",
      "|    value_loss           | 46.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.08        |\n",
      "|    ep_rew_mean          | -13.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012233006 |\n",
      "|    clip_fraction        | 0.0753      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.67       |\n",
      "|    explained_variance   | -0.0305     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.68        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    value_loss           | 21.5        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 2.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2           |\n",
      "|    mean_reward          | -9          |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011519097 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.65       |\n",
      "|    explained_variance   | -0.00571    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shaheryar\\Desktop\\EDISS\\Semester 1\\DIE 1\\bin-packing-drl\\conditional_bin_packing\\venv\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4.1      |\n",
      "|    ep_rew_mean     | -13      |\n",
      "| time/              |          |\n",
      "|    fps             | 506      |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.4         |\n",
      "|    ep_rew_mean          | -12.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010881149 |\n",
      "|    clip_fraction        | 0.0929      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.62       |\n",
      "|    explained_variance   | -0.00327    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    value_loss           | 21.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.97        |\n",
      "|    ep_rew_mean          | -11.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 520         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010020243 |\n",
      "|    clip_fraction        | 0.081       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.57       |\n",
      "|    explained_variance   | -0.00155    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.03        |\n",
      "|    ep_rew_mean          | -11         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012576275 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.51       |\n",
      "|    explained_variance   | -0.0011     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 22          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.7         |\n",
      "|    ep_rew_mean          | -10.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 526         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010728188 |\n",
      "|    clip_fraction        | 0.097       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.45       |\n",
      "|    explained_variance   | -0.000781   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.73        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0267     |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-8.80 +/- 0.40\n",
      "Episode length: 2.20 +/- 0.40\n",
      "Success rate: 0.00%\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.2         |\n",
      "|    mean_reward          | -8.8        |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012419142 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.39       |\n",
      "|    explained_variance   | -0.000348   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.54     |\n",
      "|    ep_rew_mean     | -10.1    |\n",
      "| time/              |          |\n",
      "|    fps             | 528      |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.92        |\n",
      "|    ep_rew_mean          | -9.98       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 530         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009891143 |\n",
      "|    clip_fraction        | 0.0743      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.33       |\n",
      "|    explained_variance   | -0.000347   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.78        |\n",
      "|    ep_rew_mean          | -9.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 528         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009878302 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.27       |\n",
      "|    explained_variance   | -0.0003     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.14        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    value_loss           | 18.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.71        |\n",
      "|    ep_rew_mean          | -9.09       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 530         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008965247 |\n",
      "|    clip_fraction        | 0.0849      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.23       |\n",
      "|    explained_variance   | -0.000368   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.18        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n",
      "Logging to ../logs/1677948409/ppo_Test_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.63     |\n",
      "|    ep_rew_mean     | -8.67    |\n",
      "| time/              |          |\n",
      "|    fps             | 812      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 28672    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 2.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2           |\n",
      "|    mean_reward          | -9          |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 30000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011162434 |\n",
      "|    clip_fraction        | 0.0976      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | -0.000132   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.52        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.69     |\n",
      "|    ep_rew_mean     | -8.21    |\n",
      "| time/              |          |\n",
      "|    fps             | 659      |\n",
      "|    iterations      | 2        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 30720    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.56        |\n",
      "|    ep_rew_mean          | -9.14       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 621         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010417083 |\n",
      "|    clip_fraction        | 0.0947      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.1        |\n",
      "|    explained_variance   | -0.000392   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.1         |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 3.42         |\n",
      "|    ep_rew_mean          | -8.18        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 604          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0098422095 |\n",
      "|    clip_fraction        | 0.0992       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.06        |\n",
      "|    explained_variance   | -0.00013     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.95         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.0211      |\n",
      "|    value_loss           | 12.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.76        |\n",
      "|    ep_rew_mean          | -8.64       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 596         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011946488 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.05       |\n",
      "|    explained_variance   | -0.000211   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.28        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.62        |\n",
      "|    ep_rew_mean          | -8.08       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011586471 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.03       |\n",
      "|    explained_variance   | -0.000122   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.36        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    value_loss           | 12.9        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-8.40 +/- 0.49\n",
      "Episode length: 2.60 +/- 0.49\n",
      "Success rate: 0.00%\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.6         |\n",
      "|    mean_reward          | -8.4        |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011603844 |\n",
      "|    clip_fraction        | 0.0928      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.97       |\n",
      "|    explained_variance   | -0.000199   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.28        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    value_loss           | 9.59        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.74     |\n",
      "|    ep_rew_mean     | -8.76    |\n",
      "| time/              |          |\n",
      "|    fps             | 586      |\n",
      "|    iterations      | 7        |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.83        |\n",
      "|    ep_rew_mean          | -8.27       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011237165 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.98       |\n",
      "|    explained_variance   | -0.000197   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.01        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.55        |\n",
      "|    ep_rew_mean          | -8.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011656619 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.97       |\n",
      "|    explained_variance   | -0.000211   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.57        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    value_loss           | 10.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.86        |\n",
      "|    ep_rew_mean          | -8.14       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 582         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014055742 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.93       |\n",
      "|    explained_variance   | -0.000116   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.68        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    value_loss           | 10.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.02        |\n",
      "|    ep_rew_mean          | -8.48       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 580         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010180531 |\n",
      "|    clip_fraction        | 0.0991      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.93       |\n",
      "|    explained_variance   | 0.000113    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    value_loss           | 15.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=50000, episode_reward=-8.40 +/- 0.80\n",
      "Episode length: 2.60 +/- 0.80\n",
      "Success rate: 0.00%\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.6         |\n",
      "|    mean_reward          | -8.4        |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010347588 |\n",
      "|    clip_fraction        | 0.0997      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.92       |\n",
      "|    explained_variance   | 0.000993    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.41        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    value_loss           | 9.27        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.9      |\n",
      "|    ep_rew_mean     | -8.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 579      |\n",
      "|    iterations      | 12       |\n",
      "|    time_elapsed    | 42       |\n",
      "|    total_timesteps | 51200    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.03        |\n",
      "|    ep_rew_mean          | -8.07       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 578         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010215618 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.95       |\n",
      "|    explained_variance   | 0.00512     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.79        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    value_loss           | 9.63        |\n",
      "-----------------------------------------\n",
      "Logging to ../logs/1677948409/ppo_Test_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4.11     |\n",
      "|    ep_rew_mean     | -8.19    |\n",
      "| time/              |          |\n",
      "|    fps             | 841      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 55296    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.12         |\n",
      "|    ep_rew_mean          | -7.98        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 678          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090116905 |\n",
      "|    clip_fraction        | 0.0878       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.91        |\n",
      "|    explained_variance   | 0.0244       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12           |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.0174      |\n",
      "|    value_loss           | 14.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.21        |\n",
      "|    ep_rew_mean          | -8.19       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 638         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010470916 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.9        |\n",
      "|    explained_variance   | 0.0527      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.85        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-7.40 +/- 1.36\n",
      "Episode length: 3.60 +/- 1.36\n",
      "Success rate: 0.00%\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.6        |\n",
      "|    mean_reward          | -7.4       |\n",
      "|    success_rate         | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 60000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00937181 |\n",
      "|    clip_fraction        | 0.0749     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.89      |\n",
      "|    explained_variance   | 0.0654     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.09       |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0175    |\n",
      "|    value_loss           | 11         |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4.23     |\n",
      "|    ep_rew_mean     | -7.57    |\n",
      "| time/              |          |\n",
      "|    fps             | 620      |\n",
      "|    iterations      | 4        |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.49        |\n",
      "|    ep_rew_mean          | -8.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 608         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011048239 |\n",
      "|    clip_fraction        | 0.0918      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | 0.0863      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.61        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    value_loss           | 9.38        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.5         |\n",
      "|    ep_rew_mean          | -7.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 600         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012279177 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.11        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    value_loss           | 9.26        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.77        |\n",
      "|    ep_rew_mean          | -7.33       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 603         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010474189 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | 0.0628      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.9         |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    value_loss           | 13.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.45        |\n",
      "|    ep_rew_mean          | -7.45       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 612         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008518742 |\n",
      "|    clip_fraction        | 0.0789      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.0717      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.01        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 12.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=70000, episode_reward=-6.40 +/- 1.02\n",
      "Episode length: 4.60 +/- 1.02\n",
      "Success rate: 0.00%\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.6         |\n",
      "|    mean_reward          | -6.4        |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 70000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012093084 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.81       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.21        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    value_loss           | 9.57        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4.61     |\n",
      "|    ep_rew_mean     | -7.49    |\n",
      "| time/              |          |\n",
      "|    fps             | 620      |\n",
      "|    iterations      | 9        |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 71680    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.45        |\n",
      "|    ep_rew_mean          | -7.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 622         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009724811 |\n",
      "|    clip_fraction        | 0.0814      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.0263      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.95        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 24.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.73        |\n",
      "|    ep_rew_mean          | -7.57       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 600         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009679407 |\n",
      "|    clip_fraction        | 0.0781      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.81       |\n",
      "|    explained_variance   | 0.0571      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.68        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.84        |\n",
      "|    ep_rew_mean          | -7.26       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 600         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010150765 |\n",
      "|    clip_fraction        | 0.0796      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.0384      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 23.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.67        |\n",
      "|    ep_rew_mean          | -7.63       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 594         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008670302 |\n",
      "|    clip_fraction        | 0.0779      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | 0.0887      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.99        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 14.1        |\n",
      "-----------------------------------------\n",
      "Logging to ../logs/1677948409/ppo_Test_0\n",
      "Eval num_timesteps=80000, episode_reward=-7.60 +/- 1.36\n",
      "Episode length: 3.40 +/- 1.36\n",
      "Success rate: 0.00%\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 3.4      |\n",
      "|    mean_reward     | -7.6     |\n",
      "|    success_rate    | 0        |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 80000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4.64     |\n",
      "|    ep_rew_mean     | -6.76    |\n",
      "| time/              |          |\n",
      "|    fps             | 984      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03        |\n",
      "|    ep_rew_mean          | -6.97       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 806         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008617949 |\n",
      "|    clip_fraction        | 0.0788      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.74       |\n",
      "|    explained_variance   | 0.0782      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.02        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 17.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.25        |\n",
      "|    ep_rew_mean          | -7.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 666         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013437185 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.72       |\n",
      "|    explained_variance   | 0.0652      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.28         |\n",
      "|    ep_rew_mean          | -6.72        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 552          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0099989185 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.73        |\n",
      "|    explained_variance   | 0.0643       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.25         |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.0173      |\n",
      "|    value_loss           | 21.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=90000, episode_reward=-5.80 +/- 0.75\n",
      "Episode length: 5.20 +/- 0.75\n",
      "Success rate: 0.00%\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5.2         |\n",
      "|    mean_reward          | -5.8        |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 90000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007132438 |\n",
      "|    clip_fraction        | 0.0534      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.69       |\n",
      "|    explained_variance   | 0.0246      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 34          |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4.99     |\n",
      "|    ep_rew_mean     | -6.51    |\n",
      "| time/              |          |\n",
      "|    fps             | 477      |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run Training\n",
    "is_train = True\n",
    "EPOCHS=10\n",
    "if is_train:\n",
    "    TIMESTEPS = 25000\n",
    "    iters=0\n",
    "    while iters<EPOCHS:\n",
    "        iters = iters+1\n",
    "\n",
    "        model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=f\"ppo_Test\",callback=eval_callback)\n",
    "        model.save(f\"{models_dir}/{iters}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ba9b589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "# loaded_model =PPO.load('..\\\\models\\\\1677681542\\\\50000', env=env)\n",
    "loa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9a9f85f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward:-8.35\n",
      "mean_episode_len:2.35\n",
      "defaultdict(<class 'int'>, {'BIN_OVERFLOW': 93, 'DUBLICATE_PICK': 7})\n"
     ]
    }
   ],
   "source": [
    "mean_reward,mean_episode_len,termination_cause,is_success,_=evaluate(loaded_model, env,100)\n",
    "print(f\"mean_reward:{mean_reward:.2f}\")\n",
    "print(f\"mean_episode_len:{mean_episode_len:.2f}\")\n",
    "print(termination_cause)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5c1b7459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36189bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward:5.11\n",
      "mean_episode_len:6.80\n",
      "defaultdict(<class 'int'>, {'SUCCESS': 29, 'BIN_OVERFLOW': 70, 'DUBLICATE_PICK': 1})\n",
      "Average Occupancy ratio: 76.4451724137931\n",
      "Average time per input: 0.003796532154083252\n"
     ]
    }
   ],
   "source": [
    "# evaluation over N episodes\n",
    "t1=time.time()\n",
    "mean_reward,mean_episode_len,termination_cause,is_success,avg_occupancy_ratio=evaluate(loaded_model, env,100)\n",
    "print(f\"mean_reward:{mean_reward:.2f}\")\n",
    "print(f\"mean_episode_len:{mean_episode_len:.2f}\")\n",
    "print(termination_cause)\n",
    "print(\"Average Occupancy ratio:\",np.array(avg_occupancy_ratio).mean())\n",
    "print(\"Average time per input:\",(time.time()-t1)/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0801bfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Costs: [103. 271. 685. 588. 277. 605. 205. 302. 411. 626.] All tasks sum:  4073.0000000000005\n",
      "Node capacities: [1000. 1800. 1800. 1400.]\n",
      "[2 1]\n",
      "Remaining Node capacities: [1000. 1115. 1800. 1400.]\n",
      "\n",
      "[3 2]\n",
      "Remaining Node capacities: [1000. 1115. 1212. 1400.]\n",
      "\n",
      "[9 3]\n",
      "Remaining Node capacities: [1000. 1115. 1212.  774.]\n",
      "\n",
      "[5 1]\n",
      "Remaining Node capacities: [1000.  510. 1212.  774.]\n",
      "\n",
      "[8 2]\n",
      "Remaining Node capacities: [1000.  510.  801.  774.]\n",
      "\n",
      "[1 0]\n",
      "Remaining Node capacities: [729. 510. 801. 774.]\n",
      "\n",
      "[7 0]\n",
      "Remaining Node capacities: [427. 510. 801. 774.]\n",
      "\n",
      "[4 3]\n",
      "Remaining Node capacities: [427. 510. 801. 497.]\n",
      "\n",
      "[6 2]\n",
      "Remaining Node capacities: [427. 510. 596. 497.]\n",
      "\n",
      "[0 2]\n",
      "Remaining Node capacities: [427. 510. 493. 497.]\n",
      "\n",
      "\n",
      "{'is_success': True, 'episode_len': 10, 'termination_cause': 'SUCCESS', 'assignment_status': [[1, 7], [2, 5], [3, 8, 6, 0], [9, 4]]}\n",
      "\n",
      "Assignment= [[1, 7], [2, 5], [3, 8, 6, 0], [9, 4]]\n",
      "\n",
      "Last Action: Allocating Task # 0 in Node/Bin # 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "obs=env.reset()\n",
    "\n",
    "FACTOR=env.norm_factor\n",
    "\n",
    "print(\"Task Costs:\",obs['tasks']*FACTOR,\"All tasks sum: \",sum(obs['tasks'])*FACTOR)\n",
    "print(\"Node capacities:\",obs['nodes']*FACTOR)\n",
    "\n",
    "while not done:\n",
    "    # _states are only useful when using LSTM policies\n",
    "    action, _states = loaded_model.predict(obs)\n",
    "    # here, action, rewards and dones are arrays\n",
    "    # because we are using vectorized env\n",
    "    obs, reward, done, info = env.step(action)\n",
    "#     print(\"Tasks after episodes:\",obs['tasks']*FACTOR)\n",
    "    print(action)\n",
    "    print(\"Remaining Node capacities:\",obs['nodes']*FACTOR)\n",
    "    print()\n",
    "    \n",
    "print()\n",
    "print(info)\n",
    "print()\n",
    "print(\"Assignment=\",info['assignment_status'])\n",
    "print()\n",
    "print(f\"Last Action: Allocating Task # {action[0]} in Node/Bin # {action[1]}\")\n",
    "print()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbe0c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_node_capacities=obs['nodes']*FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4b55d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_occupancy=round(100-np.mean((np.array(remaining_node_capacities) /np.array([800,1000,1200,1400,1600])))*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8030045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_occupancy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a36281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
